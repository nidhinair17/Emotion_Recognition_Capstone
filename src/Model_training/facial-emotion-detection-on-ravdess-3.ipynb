{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10823529,"sourceType":"datasetVersion","datasetId":6720516},{"sourceId":10830968,"sourceType":"datasetVersion","datasetId":6725530}],"dockerImageVersionId":30888,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport tensorflow as tf\nfrom keras.applications import VGG16\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, Input, Concatenate, Conv2D, BatchNormalization\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Dense, Dropout, LSTM, GRU\nfrom tensorflow.keras.utils import to_categorical\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_ravdess_data():\n    emotion_files = {'neutral': '/kaggle/input/ravdess-features/Neutral.xlsx',\n                     'calm': '/kaggle/input/ravdess-features/Calm.xlsx',\n                     'happy': '/kaggle/input/ravdess-features/Happy.xlsx',\n                     'sad': '/kaggle/input/ravdess-features/Sad.xlsx',\n                     'angry': '/kaggle/input/ravdess-features/Angry.xlsx',\n                     'fearful': '/kaggle/input/ravdess-features/Fearful.xlsx',\n                     'disgust': '/kaggle/input/ravdess-features/Disgusted.xlsx',\n                     'surprised': '/kaggle/input/ravdess-features/Surprised.xlsx'}\n    \n    all_data = []\n    \n    for emotion, file_path in emotion_files.items():\n        try:\n            df = pd.read_excel(file_path)\n            df['emotion'] = emotion\n            all_data.append(df)\n            print(f\"Loaded {emotion} data: {len(df)} samples\")\n        except Exception as e:\n            print(f\"Error loading {emotion} file: {str(e)}\")\n    \n    combined_df = pd.concat(all_data, ignore_index=True)\n    \n    feature_columns = ['face_x', 'face_y', 'face_width', 'face_height', 'face_aspect_ratio',\n                       'left_eye_x', 'left_eye_y', 'left_eye_width', 'left_eye_height',\n                       'right_eye_x', 'right_eye_y', 'right_eye_width', 'right_eye_height',\n                       'eye_separation', 'mouth_x', 'mouth_y', 'mouth_width', 'mouth_height',\n                       'mouth_aspect_ratio', 'avg_intensity', 'intensity_variance']\n    \n    print(\"\\nDataset Statistics:\")\n    print(f\"Total samples: {len(combined_df)}\")\n    print(\"\\nSamples per emotion:\")\n    print(combined_df['emotion'].value_counts())\n    \n    X = combined_df[feature_columns].values\n    \n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(combined_df['emotion'])\n    \n    return X, y, label_encoder","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class EmotionDetectionModels:\n    def __init__(self, X, y, label_encoder):\n        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n            X, y, test_size = 0.2, random_state = 42, stratify = y)\n        \n        self.scaler = StandardScaler()\n        self.X_train_scaled = self.scaler.fit_transform(self.X_train)\n        self.X_test_scaled = self.scaler.transform(self.X_test)\n        \n        self.y_train_cat = to_categorical(self.y_train)\n        self.y_test_cat = to_categorical(self.y_test)\n        self.label_encoder = label_encoder\n        \n        self.results = {}\n        print(self.X_train)\n        print(self.X_train_scaled)\n        print(f\"\\nTraining set shape: {self.X_train.shape}\")\n        print(f\"Testing set shape: {self.X_test.shape}\")\n        \n    def create_model(self):\n        inputs = Input(shape = (self.X_train.shape[1],))\n        \n        x = Dense(256, activation = 'relu')(inputs)\n        x = BatchNormalization()(x)\n        x = Dropout(0.3)(x)\n        \n        x = Dense(128, activation = 'relu')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.3)(x)\n        \n        x = Dense(64, activation = 'relu')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.3)(x)\n        \n        outputs = Dense(8, activation = 'softmax')(x)\n        \n        model = Model(inputs = inputs, outputs = outputs)\n        model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n        model.summary()\n        return model\n    \n    def create_lstm(self):\n        X_train_reshaped = self.X_train_scaled.reshape((self.X_train_scaled.shape[0], 1, self.X_train_scaled.shape[1]))\n        X_test_reshaped = self.X_test_scaled.reshape((self.X_test_scaled.shape[0], 1, self.X_test_scaled.shape[1]))\n        \n        model = Sequential([\n            LSTM(128, input_shape = (1, self.X_train.shape[1])),\n            Dropout(0.3),\n            Dense(64, activation = 'relu'),\n            Dropout(0.2),\n            Dense(8, activation = 'softmax')\n        ])\n        model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\n        return model, X_train_reshaped, X_test_reshaped\n\n    def create_gru(self):\n        X_train_reshaped = self.X_train_scaled.reshape((self.X_train_scaled.shape[0], 1, self.X_train_scaled.shape[1]))\n        X_test_reshaped = self.X_test_scaled.reshape((self.X_test_scaled.shape[0], 1, self.X_test_scaled.shape[1]))\n        \n        model = Sequential([\n            GRU(128, input_shape=(1, self.X_train.shape[1])),\n            Dropout(0.3),\n            Dense(64, activation='relu'),\n            Dropout(0.2),\n            Dense(8, activation='softmax')\n        ])\n        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n        return model, X_train_reshaped, X_test_reshaped\n\n    def plot_confusion_matrix(self, conf_matrix, title, emotion_labels):\n        plt.figure(figsize=(10, 8))\n        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n                    xticklabels=emotion_labels, yticklabels=emotion_labels)\n        plt.title(title)\n        plt.ylabel('True Label')\n        plt.xlabel('Predicted Label')\n        plt.show()\n\n    def plot_training_history(self, history, title):\n        plt.figure(figsize=(12, 4))\n        \n        plt.subplot(1, 2, 1)\n        plt.plot(history['accuracy'], label='Training Accuracy')\n        plt.plot(history['val_accuracy'], label='Validation Accuracy')\n        plt.title(f'{title} - Accuracy')\n        plt.legend()\n        \n        plt.subplot(1, 2, 2)\n        plt.plot(history['loss'], label='Training Loss')\n        plt.plot(history['val_loss'], label='Validation Loss')\n        plt.title(f'{title} - Loss')\n        plt.legend()\n        \n        plt.tight_layout()\n        plt.show()\n\n    def train_and_evaluate(self, model_name, model, X_train, X_test, epochs=1000, batch_size=32):\n        print(f\"\\nTraining {model_name}...\")\n        \n        history = model.fit(\n            X_train, self.y_train_cat,\n            epochs=epochs,\n            batch_size=batch_size,\n            validation_split=0.2,\n            verbose=1\n        )\n        \n        y_pred = model.predict(X_test)\n        y_pred_classes = np.argmax(y_pred, axis=1)\n        y_test_classes = np.argmax(self.y_test_cat, axis=1)\n        \n        y_test_emotions = self.label_encoder.inverse_transform(y_test_classes)\n        y_pred_emotions = self.label_encoder.inverse_transform(y_pred_classes)\n        \n        conf_matrix = confusion_matrix(y_test_emotions, y_pred_emotions)\n        class_report = classification_report(y_test_emotions, y_pred_emotions)\n        \n        self.results[model_name] = {\n            'model': model,\n            'history': history.history,\n            'confusion_matrix': conf_matrix,\n            'classification_report': class_report,\n            'predictions': y_pred_emotions,\n            'true_labels': y_test_emotions\n        }\n\n        self.plot_training_history(history.history, model_name)\n        self.plot_confusion_matrix(conf_matrix, f'{model_name} Confusion Matrix', \n                                 self.label_encoder.classes_)\n        \n        return history, conf_matrix, class_report\n\n    def print_comparison(self):\n        print(\"\\nModel Comparison Results\")\n        print(\"=\" * 50)\n        \n        summary_data = []\n        \n        for model_name, result in self.results.items():\n            print(f\"\\n{model_name} Results\")\n            print(\"-\" * 30)\n            print(\"\\nClassification Report:\")\n            print(result['classification_report'])\n            \n            val_acc = result['history']['val_accuracy'][-1]\n            val_loss = result['history']['val_loss'][-1]\n            \n            summary_data.append({\n                'Model': model_name,\n                'Validation Accuracy': val_acc,\n                'Validation Loss': val_loss\n            })\n        \n        summary_df = pd.DataFrame(summary_data)\n        print(\"\\nSummary of Results:\")\n        print(summary_df.to_string(index=False))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X, y, label_encoder = load_ravdess_data()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"my_model = EmotionDetectionModels(X, y, label_encoder)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model = my_model.create_model()\n# my_model.train_and_evaluate(\"Model\", model, my_model.X_train_scaled, my_model.X_test_scaled)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lstm_model, X_train_reshaped, X_test_reshaped = my_model.create_lstm()\nmy_model.train_and_evaluate(\"LSTM\", lstm_model, X_train_reshaped, X_test_reshaped)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# gru_model, X_train_reshaped, X_test_reshaped = my_model.create_gru()\n# my_model.train_and_evaluate(\"GRU\", gru_model, X_train_reshaped, X_test_reshaped)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"my_model.print_comparison()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}